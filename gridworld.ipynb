{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8V-diTYgI5R4"
      },
      "outputs": [],
      "source": [
        "class GridWorld:\n",
        "    def __init__(self):\n",
        "        self.grid = [[' ' for _ in range(4)] for _ in range(4)]\n",
        "        self.agent_row = 0\n",
        "        self.agent_col = 0\n",
        "        self.goal_row = 3\n",
        "        self.goal_col = 3\n",
        "        self.actions = ['up', 'down', 'left', 'right']\n",
        "\n",
        "    def reset(self):\n",
        "        self.agent_row = 0\n",
        "        self.agent_col = 0\n",
        "        self.grid[self.agent_row][self.agent_col] = 'A'\n",
        "        self.grid[self.goal_row][self.goal_col] = 'G'\n",
        "        return self.observe()\n",
        "\n",
        "    def observe(self):\n",
        "        return self.grid\n",
        "\n",
        "    def step(self, action):\n",
        "        if action == 'up':\n",
        "            self.agent_row -= 1\n",
        "        elif action == 'down':\n",
        "            self.agent_row += 1\n",
        "        elif action == 'left':\n",
        "            self.agent_col -= 1\n",
        "        elif action == 'right':\n",
        "            self.agent_col += 1\n",
        "\n",
        "        if self.agent_row == self.goal_row and self.agent_col == self.goal_col:\n",
        "            reward = 1\n",
        "            done = True\n",
        "        else:\n",
        "            reward = 0\n",
        "            done = False\n",
        "\n",
        "        self.grid[self.agent_row][self.agent_col] = 'A'\n",
        "        self.grid[self.goal_row][self.goal_col] = 'G'\n",
        "\n",
        "        return self.observe(), reward, done\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Grid: #Environment\n",
        "    def __init__(self, width, height, start):\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "        self.i = start[0]\n",
        "        self.j = start[1]\n",
        "        self.rewards = {}\n",
        "        self.actions = {}\n",
        "\n",
        "    def set(self, rewards, actions):\n",
        "        self.rewards = rewards\n",
        "        self.actions = actions\n",
        "\n",
        "    def set_state(self, s):\n",
        "        self.i = s[0]\n",
        "        self.j = s[1]\n",
        "\n",
        "    def current_state(self):\n",
        "        return (self.i, self.j)\n",
        "\n",
        "    def is_terminal(self, s):\n",
        "        return s not in self.actions\n",
        "\n",
        "    def game_over(self):\n",
        "        return (self.i, self.j) not in self.actions\n",
        "\n",
        "    def move(self, action):\n",
        "        x = self.rewards.get((self.i, self.j), -1)\n",
        "        if action in self.actions[self.i, self.j]:\n",
        "            if action == 'U' and self.i != 0:\n",
        "                self.i -= 1\n",
        "            elif action == 'D' and self.i != self.height - 1:\n",
        "                self.i += 1\n",
        "            elif action == 'R' and self.j != self.width - 1:\n",
        "                self.j += 1\n",
        "            elif action == 'L' and self.j != 0:\n",
        "                self.j -= 1\n",
        "        return x\n",
        "\n",
        "    def all_states(self):\n",
        "        return set(list(self.actions.keys()) + list(self.rewards.keys()))\n",
        "\n",
        "    def undo_move(self, action):\n",
        "        if action == 'U':\n",
        "            self.i += 1\n",
        "        elif action == 'D':\n",
        "            self.i -= 1\n",
        "        elif action == 'R':\n",
        "            self.j -= 1\n",
        "        elif action == 'L':\n",
        "            self.j += 1\n",
        "\n",
        "#raise an exception if we arrive somewhere we shouldnt assert(self.current_state() in self.all_states())\n",
        "\n",
        "def grid():\n",
        "  grd = Grid(4, 4, (0,0))\n",
        "  rewards = {(3, 3): 0, (0,0):0}\n",
        "  actions = {\n",
        "  # (0, 0): ('L', 'U', 'D', 'R'),\n",
        "    (0, 1): ('L', 'U', 'D', 'R'),\n",
        "    (0, 2): ('L', 'U', 'D', 'R'),\n",
        "    (0, 3): ('L', 'U', 'D', 'R'),\n",
        "    (1, 0): ('L', 'U', 'D', 'R'),\n",
        "    (1, 1): ('L', 'U', 'D', 'R'),\n",
        "    (1, 2): ('L', 'U', 'D', 'R'),\n",
        "    (1, 3): ('L', 'U', 'D', 'R'),\n",
        "    (2, 0): ('L', 'U', 'D', 'R'),\n",
        "    (2, 1): ('L', 'U', 'D', 'R'),\n",
        "    (2, 2): ('L', 'U', 'D', 'R'),\n",
        "    (2, 3): ('L', 'U', 'D', 'R'),\n",
        "    (3, 0): ('L', 'U', 'D', 'R'),\n",
        "    (3, 1): ('L', 'U', 'D', 'R'),\n",
        "    (3, 2): ('L', 'U', 'D', 'R'),\n",
        "    # (3, 3): ('L', 'U', 'D', 'R'),\n",
        "  }\n",
        "  grd.set(rewards, actions)\n",
        "  return grd\n",
        "\n"
      ],
      "metadata": {
        "id": "fHZsD_TUKXEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def iterative_policy_evaluation(env, policy, gamma=1, theta=1e-6):\n",
        "    V = {}  # State value function\n",
        "    for s in env.all_states():\n",
        "        V[s] = 0\n",
        "\n",
        "    num_iterations = 0\n",
        "    while True:\n",
        "        delta = 0\n",
        "        for s in env.all_states():\n",
        "            if not env.is_terminal(s):\n",
        "                v = V[s]\n",
        "                new_v = 0\n",
        "                for action in policy[s]:\n",
        "                    env.set_state(s)\n",
        "                    reward = env.move(action)\n",
        "                    new_v += policy[s][action] * (reward + gamma * V[env.current_state()])\n",
        "                V[s] = new_v\n",
        "                delta = max(delta, abs(v - V[s]))\n",
        "        num_iterations += 1\n",
        "        if delta < theta:\n",
        "            break\n",
        "\n",
        "    return V, num_iterations"
      ],
      "metadata": {
        "id": "zPXDC66Q85L6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "policy = {}\n",
        "for s in grid().all_states():\n",
        "    if not grid().is_terminal(s):\n",
        "        policy[s] = {'U': 0.25, 'D': 0.25, 'L': 0.25, 'R': 0.25}\n",
        "\n",
        "# Create the Grid environment\n",
        "env = grid()\n",
        "\n",
        "# Perform Iterative Policy Evaluation\n",
        "values, iterations = iterative_policy_evaluation(env, policy)\n",
        "\n",
        "print(\"State Values:\")\n",
        "for i in range(env.height):\n",
        "    for j in range(env.width):\n",
        "        print(f\"({i}, {j}): {values[(i, j)]}\")\n",
        "print(\"Number of iterations:\", iterations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NHGV3BV9XWN",
        "outputId": "1c62fb55-ec4f-4bcc-9b12-360a48439276"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "State Values:\n",
            "(0, 0): 0\n",
            "(0, 1): -13.999993685513497\n",
            "(0, 2): -19.999990922080737\n",
            "(0, 3): -21.999989094053294\n",
            "(1, 0): -13.999994214722694\n",
            "(1, 1): -17.999992251296543\n",
            "(1, 2): -19.999990817079592\n",
            "(1, 3): -19.99999092208074\n",
            "(2, 0): -19.99999092208074\n",
            "(2, 1): -19.999990817079592\n",
            "(2, 2): -17.999992251296543\n",
            "(2, 3): -13.999993685513495\n",
            "(3, 0): -21.99999000806702\n",
            "(3, 1): -19.99999092208074\n",
            "(3, 2): -13.999994214722696\n",
            "(3, 3): 0\n",
            "Number of iterations: 167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Grid: # Environment\n",
        "    def __init__(self, width, height, start):\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "        self.i = start[0]\n",
        "        self.j = start[1]\n",
        "        self.rewards = {}\n",
        "        self.actions = {}\n",
        "\n",
        "    def set(self, rewards, actions):\n",
        "        self.rewards = rewards\n",
        "        self.actions = actions\n",
        "\n",
        "    def set_state(self, s):\n",
        "        self.i = s[0]\n",
        "        self.j = s[1]\n",
        "\n",
        "    def current_state(self):\n",
        "        return (self.i, self.j)  # Return the tuple directly\n",
        "\n",
        "    def is_terminal(self, s):\n",
        "        return s not in self.actions\n",
        "\n",
        "    def game_over(self):\n",
        "        return (self.i, self.j) not in self.actions\n",
        "\n",
        "    def move(self, action):\n",
        "        x = self.rewards.get((self.i, self.j), -1)\n",
        "        if action in self.actions[self.i, self.j]:\n",
        "            if action == 'U' and self.i != 0:\n",
        "                self.i -= 1\n",
        "            elif action == 'D' and self.i != self.height - 1:\n",
        "                self.i += 1\n",
        "            elif action == 'R' and self.j != self.width - 1:\n",
        "                self.j += 1\n",
        "            elif action == 'L' and self.j != 0:\n",
        "                self.j -= 1\n",
        "            next_state = (self.i, self.j)  # Update next_state\n",
        "        return x, next_state\n",
        "\n",
        "    def all_states(self):\n",
        "        return set(list(self.actions.keys()) + list(self.rewards.keys()))\n",
        "\n",
        "    def undo_move(self, action):\n",
        "        if action == 'U':\n",
        "            self.i += 1\n",
        "        elif action == 'D':\n",
        "            self.i -= 1\n",
        "        elif action == 'R':\n",
        "            self.j -= 1\n",
        "        elif action == 'L':\n",
        "            self.j += 1\n",
        "\n"
      ],
      "metadata": {
        "id": "ZY8t-SrY-xs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def iterative_policy_evaluation(env, policy, gamma=1, theta=1e-6):\n",
        "    V = {}  # State value function\n",
        "    for s in env.all_states():\n",
        "        V[s] = 0\n",
        "\n",
        "    while True:\n",
        "        delta = 0\n",
        "        for s in env.all_states():\n",
        "            if not env.is_terminal(s):\n",
        "                v = V[s]\n",
        "                new_v = 0\n",
        "                for action in policy[s]:\n",
        "                    env.set_state(s)\n",
        "                    reward, next_state = env.move(action)  # Unpack reward and next state\n",
        "                    new_v += policy[s][action] * (reward + gamma * V[next_state])  # Update new_v using reward and next state\n",
        "                V[s] = new_v\n",
        "                delta = max(delta, abs(v - V[s]))\n",
        "        if delta < theta:\n",
        "            break\n",
        "\n",
        "    return V\n",
        "\n",
        "def policy_improvement(env, V, gamma=1):\n",
        "    policy = {}\n",
        "    for s in env.all_states():\n",
        "        if not env.is_terminal(s):\n",
        "            actions = env.actions[s]\n",
        "            best_action = None\n",
        "            best_value = float('-inf')\n",
        "            for action in actions:\n",
        "                env.set_state(s)\n",
        "                reward, next_state = env.move(action)  # Unpack reward and next state\n",
        "                value = reward + gamma * V[next_state]  # Update value using unpacked reward and next state\n",
        "                if value > best_value:\n",
        "                    best_value = value\n",
        "                    best_action = action\n",
        "            policy[s] = {a: 1 if a == best_action else 0 for a in actions}\n",
        "    return policy\n",
        "\n",
        "\n",
        "def policy_iteration(env, gamma=1, theta=1e-6):\n",
        "    policy = {}\n",
        "    for s in env.all_states():\n",
        "        if not env.is_terminal(s):\n",
        "            policy[s] = {a: 0.25 for a in env.actions[s]}  # Initialize with random policy\n",
        "\n",
        "    while True:\n",
        "        V = iterative_policy_evaluation(env, policy, gamma, theta)\n",
        "        new_policy = policy_improvement(env, V, gamma)\n",
        "        if new_policy == policy:\n",
        "            break\n",
        "        policy = new_policy\n",
        "\n",
        "    return policy, V"
      ],
      "metadata": {
        "id": "T60hqbwe9aJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = grid()\n",
        "\n",
        "# Perform Policy Iteration\n",
        "policy, values = policy_iteration(env)\n",
        "\n",
        "# Print the resulting policy and state values\n",
        "print(\"Policy:\")\n",
        "for i in range(env.height):\n",
        "    for j in range(env.width):\n",
        "        print(f\"({i}, {j}): {policy.get((i, j), 'Terminal')}\")\n",
        "print(\"\\nState Values:\")\n",
        "for i in range(env.height):\n",
        "    for j in range(env.width):\n",
        "        print(f\"({i}, {j}): {values.get((i, j), 'Terminal')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1liCEi1d-boL",
        "outputId": "fe2ffd02-b913-406b-d11e-592b4db09de8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Policy:\n",
            "(0, 0): Terminal\n",
            "(0, 1): {'L': 1, 'U': 0, 'D': 0, 'R': 0}\n",
            "(0, 2): {'L': 1, 'U': 0, 'D': 0, 'R': 0}\n",
            "(0, 3): {'L': 1, 'U': 0, 'D': 0, 'R': 0}\n",
            "(1, 0): {'L': 0, 'U': 1, 'D': 0, 'R': 0}\n",
            "(1, 1): {'L': 1, 'U': 0, 'D': 0, 'R': 0}\n",
            "(1, 2): {'L': 1, 'U': 0, 'D': 0, 'R': 0}\n",
            "(1, 3): {'L': 0, 'U': 0, 'D': 1, 'R': 0}\n",
            "(2, 0): {'L': 0, 'U': 1, 'D': 0, 'R': 0}\n",
            "(2, 1): {'L': 1, 'U': 0, 'D': 0, 'R': 0}\n",
            "(2, 2): {'L': 0, 'U': 0, 'D': 1, 'R': 0}\n",
            "(2, 3): {'L': 0, 'U': 0, 'D': 1, 'R': 0}\n",
            "(3, 0): {'L': 0, 'U': 1, 'D': 0, 'R': 0}\n",
            "(3, 1): {'L': 0, 'U': 0, 'D': 0, 'R': 1}\n",
            "(3, 2): {'L': 0, 'U': 0, 'D': 0, 'R': 1}\n",
            "(3, 3): Terminal\n",
            "\n",
            "State Values:\n",
            "(0, 0): 0\n",
            "(0, 1): -1\n",
            "(0, 2): -2\n",
            "(0, 3): -3\n",
            "(1, 0): -1\n",
            "(1, 1): -2\n",
            "(1, 2): -3\n",
            "(1, 3): -2\n",
            "(2, 0): -2\n",
            "(2, 1): -3\n",
            "(2, 2): -2\n",
            "(2, 3): -1\n",
            "(3, 0): -3\n",
            "(3, 1): -2\n",
            "(3, 2): -1\n",
            "(3, 3): 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def value_iteration(env, gamma=1, theta=1e-6):\n",
        "    V = {}  # State value function\n",
        "    for s in env.all_states():\n",
        "        V[s] = 0\n",
        "\n",
        "    while True:\n",
        "        delta = 0\n",
        "        for s in env.all_states():\n",
        "            if not env.is_terminal(s):\n",
        "                v = V[s]\n",
        "                max_value = float('-inf')\n",
        "                for action in env.actions[s]:\n",
        "                    env.set_state(s)\n",
        "                    reward, next_state = env.move(action)\n",
        "                    value = reward + gamma * V[next_state]\n",
        "                    max_value = max(max_value, value)\n",
        "                V[s] = max_value\n",
        "                delta = max(delta, abs(v - V[s]))\n",
        "        if delta < theta:\n",
        "            break\n",
        "\n",
        "    # Policy Improvement\n",
        "    policy = {}\n",
        "    for s in env.all_states():\n",
        "        if not env.is_terminal(s):\n",
        "            actions = env.actions[s]\n",
        "            best_action = None\n",
        "            best_value = float('-inf')\n",
        "            for action in actions:\n",
        "                env.set_state(s)\n",
        "                reward, next_state = env.move(action)\n",
        "                value = reward + gamma * V[next_state]\n",
        "                if value > best_value:\n",
        "                    best_value = value\n",
        "                    best_action = action\n",
        "            policy[s] = {a: 1 if a == best_action else 0 for a in actions}\n",
        "\n",
        "    return policy, V\n",
        "\n",
        "# Perform Value Iteration\n",
        "policy_vi, values_vi = value_iteration(env)\n",
        "\n",
        "# Print the resulting policy and state values\n",
        "print(\"Policy (Value Iteration):\")\n",
        "for i in range(env.height):\n",
        "    for j in range(env.width):\n",
        "        print(f\"({i}, {j}): {policy_vi.get((i, j), 'Terminal')}\")\n",
        "print(\"\\nState Values (Value Iteration):\")\n",
        "for i in range(env.height):\n",
        "    for j in range(env.width):\n",
        "        print(f\"({i}, {j}): {values_vi.get((i, j), 'Terminal')}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8E3h-J7P-lgm",
        "outputId": "88240c3a-1d18-4d33-e0ff-a48e79f89608"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Policy (Value Iteration):\n",
            "(0, 0): Terminal\n",
            "(0, 1): {'L': 1, 'U': 0, 'D': 0, 'R': 0}\n",
            "(0, 2): {'L': 1, 'U': 0, 'D': 0, 'R': 0}\n",
            "(0, 3): {'L': 1, 'U': 0, 'D': 0, 'R': 0}\n",
            "(1, 0): {'L': 0, 'U': 1, 'D': 0, 'R': 0}\n",
            "(1, 1): {'L': 1, 'U': 0, 'D': 0, 'R': 0}\n",
            "(1, 2): {'L': 1, 'U': 0, 'D': 0, 'R': 0}\n",
            "(1, 3): {'L': 0, 'U': 0, 'D': 1, 'R': 0}\n",
            "(2, 0): {'L': 0, 'U': 1, 'D': 0, 'R': 0}\n",
            "(2, 1): {'L': 1, 'U': 0, 'D': 0, 'R': 0}\n",
            "(2, 2): {'L': 0, 'U': 0, 'D': 1, 'R': 0}\n",
            "(2, 3): {'L': 0, 'U': 0, 'D': 1, 'R': 0}\n",
            "(3, 0): {'L': 0, 'U': 1, 'D': 0, 'R': 0}\n",
            "(3, 1): {'L': 0, 'U': 0, 'D': 0, 'R': 1}\n",
            "(3, 2): {'L': 0, 'U': 0, 'D': 0, 'R': 1}\n",
            "(3, 3): Terminal\n",
            "\n",
            "State Values (Value Iteration):\n",
            "(0, 0): 0\n",
            "(0, 1): -1\n",
            "(0, 2): -2\n",
            "(0, 3): -3\n",
            "(1, 0): -1\n",
            "(1, 1): -2\n",
            "(1, 2): -3\n",
            "(1, 3): -2\n",
            "(2, 0): -2\n",
            "(2, 1): -3\n",
            "(2, 2): -2\n",
            "(2, 3): -1\n",
            "(3, 0): -3\n",
            "(3, 1): -2\n",
            "(3, 2): -1\n",
            "(3, 3): 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1UcytQd-_7um"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}